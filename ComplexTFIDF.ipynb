{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex TFIDF\n",
    "\n",
    "\n",
    "## A review of TFIDF\n",
    "\n",
    "(Skip ahead if you're familiar with TF-IDF)\n",
    "\n",
    "TFIDF is an embedding algorithm that converts a list of documents into vectors whose components correspond to the terms comprising each document and the values of the components reflect the frequency of that terms in the document as well as how common it is over all documents. By a \"term\"\", we could mean words or other units of text like bigrams or ngrams, so splitting \"hello world\" by words would return tokens \"hello\" and \"world\", whereas splitting by bigrams would return \"he\",\"el\",\"ll\",...,\"ld\". \n",
    "\n",
    "Let's recall the definition of TFIDF explicitly. Consider a list of $N$ documents $d_1,...,d_N$, where each document $d_i$ is comprised of a subset of terms from a set of distinct terms $T$ (the dictionary), each term $t\\in T$ appearing $tf_i(t)$ in the document $d_i$ (the *term frequency*) and appearing in $N(t)$ documents. If we enumerate the dictionary $T$ as $t_{1},...,t_{D}$, then the Term Frequency-Inverse Document Frequency (TF-IDF) representation of the document $d_i$ is the vector in $\\mathbb{R}^{D}$ whose $i$th component is\n",
    "\n",
    "$$ tf_{i}(t)\\log\\frac{N}{N(t)}.$$\n",
    "\n",
    "(Note that one can also normalize $tf_i(t)$ to be the proportion of times $t$ appears in document $i$ rather than the number, but we will work with this definition.)\n",
    "\n",
    "This represents a document in such a way that the dominant components correspond to terms that appear frequently in the document that are rare overall while suppressing the values of very common terms. Imagining the documents in question are pages of wikipedia, components corresponding to terms like \"the\" and \"is\" will have small values since these terms are in most every page, so the inverse document frequency $N/N(t)$ will be close to $1$ and hence the logarithm will be close to zero, whereas terms like \"Mingus\" and \"heteroskadicity\" are quite rare overall, making the logarithm much larger. \n",
    "\n",
    "Of course, there are more sophisticated text embeddings that encode context and meaning of a document (noteably BERT and its siblings), so that \"The War of the Worlds\" and \"The Battle of the Planets\" will have close representations (at least more so in comparison to unrelated sentences) than they would with a TF-IDF representation. In particular, the order of terms matter, so the representations of \"the dog caught the ball\" and \"the ball caught the dog\" would be different, whereas the TF-IDF representations would be identical. However, TF-IDF is a lightweight, transparent representation that is still very useful.\n",
    "\n",
    "TF-IDF is also good at representing short strings when using bigrams (or ngrams) as the terms rather than words: now the components of the embeddings correspond to bigrams (so for \"amazon\", the nonzero components will correspond to \"am\",\"ma\",\"az\",...). One reason is that it can be forgiving of alternate spellings of words (e.g. \"amazoncom\", \"amazon.com\", \"amazon com\" will have similar representations). \n",
    "\n",
    "## Adding order to TF-IDF wtih complex numbers.\n",
    "\n",
    "One question I thought about was whether one could come up with a TF-IDF-like representation that somehow encodes the position of the terms, but without having to use something as complex as Attention or Transformers. A cheap way of doing this is using complex numbers. \n",
    "\n",
    "Let's assume all our documents have length at most $M$, that is, each document $d_i$ is an ordered list of terms $t_{i,1},...,t_{i,m_i}$ (where $t_{i,j}\\in T$ and $m_i\\leq M$ and the terms may repeat. If $e_{i,j}$ is the standard basis vector corresponding to the term $t_{i,j}$, we define a complex TF-IDf representation of $d_i$ as \n",
    "\n",
    "$$CTFIDF(d_i) = \\sum_{j=1}^{m_i} e^{\\frac{\\pi ij}{4M}} \\log\\frac{N}{N(t_{i,j})}$$\n",
    "\n",
    "Some remarks\n",
    "\n",
    "1. Without the complex exponential this would just return the usual TFIDF. \n",
    "2. Note that this is effectively a vector in $\\mathbb{R}^{D}\\times i\\mathbb{R}^{D}\\equiv \\mathbb{R}^{2D}$, so we have only doubled the dimension of the representation.\n",
    "3. It is not hard to show that, if each term appears exactly once in $d_i$, then $|TFIDF(d_i)| = |CTFIDF(d_i)|$, however now it is possible to\n",
    " have strings with identical TFIDF representation but distinct CTFIDF. \n",
    "\n",
    "# Demonstration\n",
    "\n",
    "Below we use a custom tfidf object that can do both traditional and complex tfidf. As a demonstration, we fit it on the words in the above text.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jazzam/opt/anaconda3/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tfidf import TFIDF\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TFIDF(gramlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 605/605 [00:00<00:00, 11411.92it/s]\n"
     ]
    }
   ],
   "source": [
    "d = open(\"text.txt\",\"r\").read()\n",
    "d = re.findall(\"[a-z]{2,}\",d)\n",
    "df = pd.DataFrame({\"text\":d})\n",
    "tfidf.fit(df,\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tfidf object has a 'show' method that shows the unnormalized tfidf representation of a word. Note that \"ja\" is out of dictionary and doesn't appear in the representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' l', 6.921578957728802)\n",
      "('ll', 6.721412040614837)\n",
      "('la', 9.591581091193483)\n",
      "('am', 11.760965424728523)\n",
      "('ma', 10.897919207373182)\n",
      "('a ', 17.13624383241269)\n",
      "(' r', 3.004031076368686)\n",
      "('re', 2.185720752854735)\n",
      "('ed', 4.208003880694622)\n",
      "('d ', 2.794310545386617)\n",
      "(' p', 4.459318308975528)\n",
      "('pa', 4.795790545596741)\n"
     ]
    }
   ],
   "source": [
    "tfidf.show(\"llama llama red pajama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the complex tfidf representation. Below instead of having a number for each component, we have the real and complex part. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' l', 6.544375483375044, 1.571165545003015)\n",
      "('ll', 6.215819018726448, 2.019642027403319)\n",
      "('la', 8.616622458672762, 3.569121884230861)\n",
      "('am', 6.793039094674124, 7.381548106389901)\n",
      "('ma', 5.738496254087156, 7.312653123404562)\n",
      "('a ', 8.093408638945665, 12.171175626881828)\n",
      "(' r', 1.765725164117798, 2.430312192412732)\n",
      "('re', 1.1420359562364624, 1.8636333019462112)\n",
      "('ed', 1.9103937847025037, 3.749358911508878)\n",
      "('d ', 1.0693363506025169, 2.5816063203631465)\n",
      "(' p', 1.378005140800791, 4.2410637359854615)\n",
      "('pa', 1.1195550688935425, 4.663282471065833)\n"
     ]
    }
   ],
   "source": [
    "tfidf.show_complex(\"llama llama red pajama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note above that \" p\" and \"pa\", since they are further along in the string, have smaller real part than they do imaginary, whereas terms appearing mostly in the first half of the string like \"ll\" have larger real part than imaginary.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A comparison of representations in clustering\n",
    "\n",
    "We demonstrate how the complex tfidf can outperform the usual tfidf using some synthetic data. Synthetic data isn't ideal, but this is just a POC and maybe at a future point we could use some realworld data for a better test. \n",
    "\n",
    "The way we evaluate this is by testing how well KMeans clustering works using each representation. We do this by creating some text consisting of some made up business names plus some noise (random words, think of the strings as transactions consiting of the business name plus an order number), label the strings by their business name, then apply KMeans with the same number of clusters as business names.\n",
    "\n",
    "Ideally, we'd expect a good clustering to return the original groups, that is, the strings that appear in each cluster all belong to one business. So a clustering that results in clusters where 90% of strings in each cluster correspond to one business might be called good. However, imagine we have two clustering that are like this, but in one clustering the remaining 10% in each cluster comes from one other business and in the other clustering the remaining 10% come from two other businesses. It would seem that the second clustering is more confused about grouping transactions together than the first, as the first is at best confusing two categories with each other in each cluster, not three. \n",
    "\n",
    "A better way of evaluating the quality of how good a clustering performs on labeled data is to look at the weighted average of the entropies of the labels in each cluster. That is, if We have N strings with labels $l_1,...,l_n$, and we cluster into $m$ clusters $C_1,...,C_m$ of sizes $N_1,...,N_m$, we consider the quantity:\n",
    "\n",
    "$$ \\sum_{i=1}^{m} H_i \\frac{N_i}{M}$$\n",
    "\n",
    "where \n",
    "\n",
    "$$H_i = \\sum_{j=1}^{n} p_{i,j}\\log \\frac{1}{p_{i,j}}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$p_{i,j}=\\frac{|\\{x\\in C_i: x\\in l_j\\}|}{|C_i|}.$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>jack and jones uuyrrbzspp</td>\n",
       "      <td>jack and jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>jones of london rpeeiebown</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>jacks of london mahjyhqvex</td>\n",
       "      <td>jacks of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>jones of london dxllvfygqt</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>jones of london ckcwntksmj</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>jack and jones ighgypzbhi</td>\n",
       "      <td>jack and jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>jones of london gmxltmvdld</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>jack and jones dtjynjgoec</td>\n",
       "      <td>jack and jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>jones of london nsnmosjhhs</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>london jacks xdchvxbjjh</td>\n",
       "      <td>london jacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jacks of london jcmdrbgnbi</td>\n",
       "      <td>jacks of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>jacks of london jvnrnvabxf</td>\n",
       "      <td>jacks of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>jack and jones hcohyugunp</td>\n",
       "      <td>jack and jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>jones of london hrkcmpzjfw</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>london jacks sjbxdmjkwt</td>\n",
       "      <td>london jacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>london jacks yylpzynlte</td>\n",
       "      <td>london jacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>jones of london klnteqavuk</td>\n",
       "      <td>jones of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>jacks of london dvucmhaecv</td>\n",
       "      <td>jacks of london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>jack and jones wfqrsacrjg</td>\n",
       "      <td>jack and jones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>jacks of london vosypnykmw</td>\n",
       "      <td>jacks of london</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text            label\n",
       "157   jack and jones uuyrrbzspp   jack and jones\n",
       "267  jones of london rpeeiebown  jones of london\n",
       "57   jacks of london mahjyhqvex  jacks of london\n",
       "226  jones of london dxllvfygqt  jones of london\n",
       "205  jones of london ckcwntksmj  jones of london\n",
       "192   jack and jones ighgypzbhi   jack and jones\n",
       "213  jones of london gmxltmvdld  jones of london\n",
       "179   jack and jones dtjynjgoec   jack and jones\n",
       "259  jones of london nsnmosjhhs  jones of london\n",
       "333     london jacks xdchvxbjjh     london jacks\n",
       "24   jacks of london jcmdrbgnbi  jacks of london\n",
       "85   jacks of london jvnrnvabxf  jacks of london\n",
       "180   jack and jones hcohyugunp   jack and jones\n",
       "210  jones of london hrkcmpzjfw  jones of london\n",
       "379     london jacks sjbxdmjkwt     london jacks\n",
       "312     london jacks yylpzynlte     london jacks\n",
       "219  jones of london klnteqavuk  jones of london\n",
       "81   jacks of london dvucmhaecv  jacks of london\n",
       "146   jack and jones wfqrsacrjg   jack and jones\n",
       "61   jacks of london vosypnykmw  jacks of london"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the synthetic data\n",
    "\n",
    "import string\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "\n",
    "def random_text(N=10):\n",
    "    return \"\".join(np.random.choice(alphabet,N))\n",
    "random_text(10)\n",
    "\n",
    "#We make up 4 business names, intentionally choosing names that are quite similar\n",
    "#but are likely to be confused by TFIDF, in the sense that the sets of bigrams will have \n",
    "#many common elements.\n",
    "\n",
    "a = \"jacks of london\"\n",
    "b = \"jack and jones\"\n",
    "c = \"jones of london\"\n",
    "d = \"london jacks\"\n",
    "\n",
    "#We create 100 distinct strings for each business, consisting of the business name\n",
    "#plus some noise word. We also create a vector with just the business name.\n",
    "X = []\n",
    "y = []\n",
    "n=100\n",
    "for z in [a,b,c,d]:\n",
    "    y = y + [z]*n\n",
    "    X = X + [z + \" \" +  random_text() for _ in range(n)]\n",
    "    \n",
    "#The TFIDF object is designed for working with dataframes, so we put the \n",
    "#text and labels into one.\n",
    "d = pd.DataFrame({\"text\":X, \"label\":y})\n",
    "    \n",
    "d.sample(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 8945.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf.fit(d,\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we cluster our data using either the tfidf or ctfidf representations, we'll\n",
    "#add the labels to the dataframe. We give here some functions to compute the entropy\n",
    "#of the cluster labels using the dataframe.\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def entropy_of_cluster(g, label_col):\n",
    "    label_counts = g[label_col].value_counts()\n",
    "    distribution = label_counts / label_counts.sum()\n",
    "    return entropy(distribution)\n",
    "    \n",
    "\n",
    "def average_entropy_of_clusters(df, label_col, cluster_col):\n",
    "    n_samples = df.shape[0]\n",
    "    return  df.groupby(cluster_col).apply(lambda g:entropy_of_cluster(g, label_col)*g.shape[0]).sum()/n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 8856.40it/s]\n",
      "100%|██████████| 400/400 [00:00<00:00, 6353.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tfidf_clusters</th>\n",
       "      <th>complex_tfidf_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jacks of london rnyzmkctup</td>\n",
       "      <td>jacks of london</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jacks of london jbcsyrdsqo</td>\n",
       "      <td>jacks of london</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jacks of london esutxrdxpk</td>\n",
       "      <td>jacks of london</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jacks of london tyfjindnnh</td>\n",
       "      <td>jacks of london</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jacks of london faapwmmtkl</td>\n",
       "      <td>jacks of london</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>london jacks ziveimoumd</td>\n",
       "      <td>london jacks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>london jacks xulqqilrza</td>\n",
       "      <td>london jacks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>london jacks ulhzmzxuph</td>\n",
       "      <td>london jacks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>london jacks uhgihofdfp</td>\n",
       "      <td>london jacks</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>london jacks tukvwrdoxf</td>\n",
       "      <td>london jacks</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           text            label  tfidf_clusters  \\\n",
       "0    jacks of london rnyzmkctup  jacks of london               0   \n",
       "1    jacks of london jbcsyrdsqo  jacks of london               3   \n",
       "2    jacks of london esutxrdxpk  jacks of london               3   \n",
       "3    jacks of london tyfjindnnh  jacks of london               3   \n",
       "4    jacks of london faapwmmtkl  jacks of london               3   \n",
       "..                          ...              ...             ...   \n",
       "395     london jacks ziveimoumd     london jacks               0   \n",
       "396     london jacks xulqqilrza     london jacks               0   \n",
       "397     london jacks ulhzmzxuph     london jacks               0   \n",
       "398     london jacks uhgihofdfp     london jacks               0   \n",
       "399     london jacks tukvwrdoxf     london jacks               3   \n",
       "\n",
       "     complex_tfidf_clusters  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "..                      ...  \n",
       "395                       2  \n",
       "396                       2  \n",
       "397                       2  \n",
       "398                       2  \n",
       "399                       2  \n",
       "\n",
       "[400 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we cluster using Kmeans and 4 clusters using both embeddigns.\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#TFIDF\n",
    "KM = KMeans(4)\n",
    "KM.fit(tfidf.transform(d.text))\n",
    "d[\"tfidf_clusters\"] = KM.labels_\n",
    "\n",
    "#CTFIDF\n",
    "KM = KMeans(4)\n",
    "KM.fit(tfidf.complex_transform(d.text))\n",
    "d[\"complex_tfidf_clusters\"] = KM.labels_\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf 0.191207720081987\n",
      "complex_tfidf 0.014025384005395172\n"
     ]
    }
   ],
   "source": [
    "for embedding in [\"tfidf\",\"complex_tfidf\"]:\n",
    "    print(embedding, average_entropy_of_clusters(d,\"label\",f\"{embedding}_clusters\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the complex tf_idf results in a clsutering of the data with much smaller entropy than with ordinary tfidf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d15eb75f864b3981c5558a26097657c62c706b3bb13c001c55722254443b6ad5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
